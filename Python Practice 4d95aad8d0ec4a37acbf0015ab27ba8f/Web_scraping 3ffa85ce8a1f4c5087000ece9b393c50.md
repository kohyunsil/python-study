# Web_scraping

ğŸ¥‘ Practice 1

```python
!pip install bs4
```

```python
from bs4 import BeautifulSoup
from urllib.request import urlopen
```

```python
url = "http://beans.itcarlow.ie/prices.html"
page = urlopen(url)
soup = BeautifulSoup(page, "html.parser")

print(soup.prettify())
```

![Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled.png](Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled.png)

```python
print(soup.find('head').prettify())

print(soup.find('body').prettify())
```

![Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%201.png](Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%201.png)

```python
print(soup.find('p').prettify())

soup.find_all('p')

soup.find_all('p')[0]

soup.find_all('p')[1]

soup.find('strong')

soup.find('strong').string

soup.find('strong').get_text()
```

![Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%202.png](Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%202.png)

ğŸ¥‘ Practice 2

```python
url = "https://finance.naver.com/marketindex/"
page = urlopen(url)

soup = BeautifulSoup(page, "html.parser")

print(soup.prettify())
```

```python
soup.find_all('span', 'value')
```

![Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%203.png](Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%203.png)

```python
soup.find_all('span', 'value')[0].string
```

![Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%204.png](Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%204.png)

ğŸ¥‘ Practice 3

```python
url = "https://book.naver.com/category/index.nhn?cate_code=280020&tab=top100&list_type=list&sort_type=publishday&page=1"
page = urlopen(url)

soup = BeautifulSoup(page, "html.parser")

print(soup.prettify())
```

```python
soup.find_all(class_='N=a:bta.title')
```

![Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%205.png](Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%205.png)

```python
soup.find_all(class_='N=a:bta.title')[0]
```

![Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%206.png](Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%206.png)

```python
# ì ‘ê·¼ì£¼ì†Œ
soup.find_all(class_='N=a:bta.title')[0]['href']

# ì±… ì œëª©
soup.find_all(class_='N=a:bta.title')[0].string

# í¬ê¸°
len(soup.find_all(class_='N=a:bta.title'))
```

```python
# ì±… ì œëª© ì €ì¥
title = [title.string for title in soup.find_all(class_='N=a:bta.title')]
title
```

![Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%207.png](Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%207.png)

```python
# í‰ì  ê¸°ë¡ (íƒœê·¸ë¡œ ë˜ì–´ìˆì§€ ì•ŠìŒ)

soup.find('dd', 'txt_desc')

soup.find('dd', 'txt_desc').get_text()
```

```python
import re

tmp = soup.find('dd', 'txt_desc').get_text()

result = re.search("\d+.(\d+)?", tmp)

if result:
    print(result.group())
```

```python
score = []

for each in soup.find_all('dd', 'txt_desc'):
    result = re.search("\d+.(\d+)?", each.get_text())
    
    score.append(result.group())

score
```

![Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%208.png](Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%208.png)

```python
# ì¶œíŒì—°ë„ ê°€ì ¸ì˜¤ê¸°

soup.find('dd', 'txt_block').get_text()
```

```python
tmp = soup.find('dd', 'txt_block').get_text()

result = re.search("\d+.\d+.\d+", tmp)

if result:
    print(result.group())
```

```python
date = []

for each in soup.find_all('dd', 'txt_block'):
    result = re.search("\d+.\d+.\d+", each.get_text())
    
    date.append(result.group())
    
date
```

![Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%209.png](Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%209.png)

```python
#ë°ì´í„° í”„ë ˆì„ìœ¼ë¡œ ë‚˜íƒ€ë‚´ê¸°
import pandas as pd

bestseller = pd.DataFrame({'ì±…ì œëª©':title, 'í‰ì ':score, 'ì¶œíŒì¼':date}, index=range(1,21))
bestseller
```

![Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%2010.png](Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%2010.png)

```python
# í‰ì  ë‘ìë¦¬ê¹Œì§€ ë‚˜íƒ€ë‚´ê¸°
pd.options.display.float_format = '{:.2f}'.format
bestseller['í‰ì '] = bestseller['í‰ì '].astype(float)
bestseller
```

![Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%2011.png](Web_scraping%203ffa85ce8a1f4c5087000ece9b393c50/Untitled%2011.png)